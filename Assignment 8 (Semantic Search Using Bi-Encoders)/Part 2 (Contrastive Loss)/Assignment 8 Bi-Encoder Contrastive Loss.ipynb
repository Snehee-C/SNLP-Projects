{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6277,"databundleVersionId":323734,"sourceType":"competition"}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-15T18:31:57.157013Z","iopub.execute_input":"2024-09-15T18:31:57.157327Z","iopub.status.idle":"2024-09-15T18:31:57.521142Z","shell.execute_reply.started":"2024-09-15T18:31:57.157292Z","shell.execute_reply":"2024-09-15T18:31:57.520181Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/quora-question-pairs/train.csv.zip\n/kaggle/input/quora-question-pairs/sample_submission.csv.zip\n/kaggle/input/quora-question-pairs/test.csv\n/kaggle/input/quora-question-pairs/test.csv.zip\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:36:55.949890Z","iopub.execute_input":"2024-09-15T18:36:55.950289Z","iopub.status.idle":"2024-09-15T18:37:10.488299Z","shell.execute_reply.started":"2024-09-15T18:36:55.950254Z","shell.execute_reply":"2024-09-15T18:37:10.486985Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Required Libraries\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom sentence_transformers import SentenceTransformer, InputExample, losses\nfrom sklearn.metrics import f1_score\nimport pandas as pd\nimport zipfile","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:37:16.757818Z","iopub.execute_input":"2024-09-15T18:37:16.758198Z","iopub.status.idle":"2024-09-15T18:37:33.403745Z","shell.execute_reply.started":"2024-09-15T18:37:16.758165Z","shell.execute_reply":"2024-09-15T18:37:33.402926Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm, trange\n","output_type":"stream"}]},{"cell_type":"code","source":"# Unzipping the train.csv.zip file\nwith zipfile.ZipFile('/kaggle/input/quora-question-pairs/train.csv.zip', 'r') as zip_ref:\n    zip_ref.extractall('/kaggle/working')\n\n# Load the extracted train.csv file\ndf = pd.read_csv('/kaggle/working/train.csv')\n\n# Preprocess the data by dropping missing values\ndf = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:37:51.952369Z","iopub.execute_input":"2024-09-15T18:37:51.953513Z","iopub.status.idle":"2024-09-15T18:37:53.883017Z","shell.execute_reply.started":"2024-09-15T18:37:51.953470Z","shell.execute_reply":"2024-09-15T18:37:53.881917Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Create examples for bi-encoder training\nexamples = []\nfor _, row in df.iterrows():\n    examples.append(InputExample(texts=[row['question1'], row['question2']], label=float(row['is_duplicate'])))","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:38:10.036456Z","iopub.execute_input":"2024-09-15T18:38:10.037325Z","iopub.status.idle":"2024-09-15T18:38:38.347770Z","shell.execute_reply.started":"2024-09-15T18:38:10.037282Z","shell.execute_reply":"2024-09-15T18:38:38.346694Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into train and validation sets (80% train, 20% validation)\ntrain_size = int(0.8 * len(examples))\ntrain_examples = examples[:train_size]\nval_examples = examples[train_size:]","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:38:38.349568Z","iopub.execute_input":"2024-09-15T18:38:38.349901Z","iopub.status.idle":"2024-09-15T18:38:38.358908Z","shell.execute_reply.started":"2024-09-15T18:38:38.349868Z","shell.execute_reply":"2024-09-15T18:38:38.357905Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Create Dataset Loaders\nclass QuoraDataset(Dataset):\n    def __init__(self, examples):\n        self.examples = examples\n\n    def __len__(self):\n        return len(self.examples)\n\n    def __getitem__(self, idx):\n        return self.examples[idx]","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:38:38.360255Z","iopub.execute_input":"2024-09-15T18:38:38.361046Z","iopub.status.idle":"2024-09-15T18:38:38.375678Z","shell.execute_reply.started":"2024-09-15T18:38:38.360996Z","shell.execute_reply":"2024-09-15T18:38:38.374837Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_dataset = QuoraDataset(train_examples)\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n\nval_dataset = QuoraDataset(val_examples)\nval_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:38:38.377204Z","iopub.execute_input":"2024-09-15T18:38:38.377511Z","iopub.status.idle":"2024-09-15T18:38:38.386751Z","shell.execute_reply.started":"2024-09-15T18:38:38.377479Z","shell.execute_reply":"2024-09-15T18:38:38.385841Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# -------- OFF-THE-SHELF MODEL EVALUATION --------\n\n# Load an off-the-shelf model without fine-tuning\noff_the_shelf_model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:38:47.060105Z","iopub.execute_input":"2024-09-15T18:38:47.060978Z","iopub.status.idle":"2024-09-15T18:38:52.490556Z","shell.execute_reply.started":"2024-09-15T18:38:47.060936Z","shell.execute_reply":"2024-09-15T18:38:52.489758Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ac1e6c93bf44c9a9308958e9da4a391"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b427203a2e644031b40ddc583925abc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/4.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09917bb4e6c041e582fe48bc06708352"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5f8fe7df80e409484feecca3e5c81e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/555 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"794c796fb67a4b14b088e9d00a8ef835"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6871c571d344132a2d02a85ed0a3a5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/505 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a5bb777ba9243d1a888f274e8664261"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe8145ff228540259a3118e2860594bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"447c38c18ecd419c8c91ed044125c595"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e5d631682fe4b9c8e19f9ee62728acf"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7a60fbf4a36426a8a78fe5126858877"}},"metadata":{}}]},{"cell_type":"code","source":"# Encode validation data\nval_q1 = [example.texts[0] for example in val_examples]\nval_q2 = [example.texts[1] for example in val_examples]","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:38:58.584817Z","iopub.execute_input":"2024-09-15T18:38:58.585217Z","iopub.status.idle":"2024-09-15T18:38:58.611889Z","shell.execute_reply.started":"2024-09-15T18:38:58.585171Z","shell.execute_reply":"2024-09-15T18:38:58.610843Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"val_q1_embeddings = off_the_shelf_model.encode(val_q1, convert_to_tensor=True)\nval_q2_embeddings = off_the_shelf_model.encode(val_q2, convert_to_tensor=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:39:07.147425Z","iopub.execute_input":"2024-09-15T18:39:07.148338Z","iopub.status.idle":"2024-09-15T18:40:45.003122Z","shell.execute_reply.started":"2024-09-15T18:39:07.148293Z","shell.execute_reply":"2024-09-15T18:40:44.998686Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2527 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b8d583ac6624e8a9fbb22d15ab10b02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2527 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cb64be8cfbd4e728c73495240a46e50"}},"metadata":{}}]},{"cell_type":"code","source":"# Compute cosine similarity between the pairs\ncosine_scores_off_the_shelf = torch.nn.functional.cosine_similarity(val_q1_embeddings, val_q2_embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:40:45.006060Z","iopub.execute_input":"2024-09-15T18:40:45.006471Z","iopub.status.idle":"2024-09-15T18:40:45.064039Z","shell.execute_reply.started":"2024-09-15T18:40:45.006428Z","shell.execute_reply":"2024-09-15T18:40:45.062817Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Define a threshold for duplicate detection (cosine similarity > threshold)\nthreshold = 0.7\ny_true = [int(example.label) for example in val_examples]\ny_pred_off_the_shelf = (cosine_scores_off_the_shelf > threshold).int().tolist()","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:40:45.065684Z","iopub.execute_input":"2024-09-15T18:40:45.066136Z","iopub.status.idle":"2024-09-15T18:40:45.112407Z","shell.execute_reply.started":"2024-09-15T18:40:45.066089Z","shell.execute_reply":"2024-09-15T18:40:45.111233Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Compute F1-Score for the off-the-shelf model\nf1_off_the_shelf = f1_score(y_true, y_pred_off_the_shelf)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:40:45.115484Z","iopub.execute_input":"2024-09-15T18:40:45.116023Z","iopub.status.idle":"2024-09-15T18:40:45.236491Z","shell.execute_reply.started":"2024-09-15T18:40:45.115974Z","shell.execute_reply":"2024-09-15T18:40:45.235376Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(f\"F1-Score for Off-the-Shelf Model: {f1_off_the_shelf:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:40:45.237834Z","iopub.execute_input":"2024-09-15T18:40:45.238266Z","iopub.status.idle":"2024-09-15T18:40:45.243933Z","shell.execute_reply.started":"2024-09-15T18:40:45.238214Z","shell.execute_reply":"2024-09-15T18:40:45.242862Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"F1-Score for Off-the-Shelf Model: 0.6811\n","output_type":"stream"}]},{"cell_type":"code","source":"# -------- FINE-TUNING THE MODEL --------\n\n# Load a pre-trained model for fine-tuning\nfine_tuned_model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n\n# Define Contrastive Loss\ntrain_loss = losses.ContrastiveLoss(model=fine_tuned_model)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:40:45.245497Z","iopub.execute_input":"2024-09-15T18:40:45.246217Z","iopub.status.idle":"2024-09-15T18:40:46.627605Z","shell.execute_reply.started":"2024-09-15T18:40:45.246158Z","shell.execute_reply":"2024-09-15T18:40:46.626857Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fine-tune the model\nfine_tuned_model.fit(\n    train_objectives=[(train_dataloader, train_loss)],\n    epochs=2,  # Increase epochs for better results\n    warmup_steps=100,\n    output_path=\"./output\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:42:19.829824Z","iopub.execute_input":"2024-09-15T18:42:19.830221Z","iopub.status.idle":"2024-09-15T19:39:51.723232Z","shell.execute_reply.started":"2024-09-15T18:42:19.830178Z","shell.execute_reply":"2024-09-15T19:39:51.722004Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10108' max='10108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10108/10108 57:23, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.016900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.014900</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.014100</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.013600</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.013000</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.012900</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.012600</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.012300</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.012200</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.012200</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.010700</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.010200</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.009800</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.009700</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.009500</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.009400</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.009400</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.009300</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>0.009300</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.009400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"# Encode validation data using fine-tuned model\nval_q1_embeddings_fine_tuned = fine_tuned_model.encode(val_q1, convert_to_tensor=True)\nval_q2_embeddings_fine_tuned = fine_tuned_model.encode(val_q2, convert_to_tensor=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T19:39:51.725555Z","iopub.execute_input":"2024-09-15T19:39:51.726001Z","iopub.status.idle":"2024-09-15T19:41:37.910889Z","shell.execute_reply.started":"2024-09-15T19:39:51.725950Z","shell.execute_reply":"2024-09-15T19:41:37.909773Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2527 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe067ed77856403d97760e372998439b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2527 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15b9334824af4a57a0da365654b22942"}},"metadata":{}}]},{"cell_type":"code","source":"# Compute cosine similarity using fine-tuned model\ncosine_scores_fine_tuned = torch.nn.functional.cosine_similarity(val_q1_embeddings_fine_tuned, val_q2_embeddings_fine_tuned)\n\n# Predict duplicates based on similarity scores using the same threshold\ny_pred_fine_tuned = (cosine_scores_fine_tuned > threshold).int().tolist()\n\n# Compute F1-Score for the fine-tuned model\nf1_fine_tuned = f1_score(y_true, y_pred_fine_tuned)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T19:41:37.914902Z","iopub.execute_input":"2024-09-15T19:41:37.915207Z","iopub.status.idle":"2024-09-15T19:41:38.033563Z","shell.execute_reply.started":"2024-09-15T19:41:37.915174Z","shell.execute_reply":"2024-09-15T19:41:38.032488Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(f\"F1-Score for Fine-Tuned Model: {f1_fine_tuned:.4f}\")\n\n# -------- COMPARISON --------\nprint(f\"\\nOff-the-Shelf Model F1-Score: {f1_off_the_shelf:.4f}\")\nprint(f\"Fine-Tuned Model F1-Score: {f1_fine_tuned:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T19:41:38.036395Z","iopub.execute_input":"2024-09-15T19:41:38.036853Z","iopub.status.idle":"2024-09-15T19:41:38.044778Z","shell.execute_reply.started":"2024-09-15T19:41:38.036799Z","shell.execute_reply":"2024-09-15T19:41:38.043856Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"F1-Score for Fine-Tuned Model: 0.8344\n\nOff-the-Shelf Model F1-Score: 0.6811\nFine-Tuned Model F1-Score: 0.8344\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}